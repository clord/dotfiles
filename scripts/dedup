#!/usr/bin/env ruby
require 'digest/sha1'
require 'pathname'
require 'sqlite3'
require 'fileutils'
require 'base64'
include FileUtils

db = nil
if File.exist? "#{ENV['HOME']}/tmp/dedup_files.db"
   # TODO: Prompt to reuse the file
 #  rm "#{ENV['HOME']}/tmp/dedup_files.db"
   db = SQLite3::Database.new("#{ENV['HOME']}/tmp/dedup_files.db")
else
   db = SQLite3::Database.new("#{ENV['HOME']}/tmp/dedup_files.db")
   db.execute("create table files(filesize integer not null, init_digest varchar(40) null, full_digest varchar(40), path varchar(4096) not null)")
   db.execute("create        index filesize_index on files (filesize)")
   db.execute("create        index init_index on files (init_digest)")
   db.execute("create unique index path_index on files (path)")
end

CLEAR = `tput el`

def print_clear(str)
  str = str.to_s
  str = ("..." + str[-80..-1]) if str.length >= 80
  STDERR.print "\r#{CLEAR}#{str}"
end

def scan_dir(db, d, &block)
  d.children.each do |path|
    print_clear(path)
    if path.directory?
      scan_dir(db, path, &block)
      next
    end
    next unless (path.exist? && path.file? && path.readable?)
    next if db.execute("SELECT 1 FROM files WHERE path = ?", path.realpath.to_s).length > 0
    block.call(path)
  end
end

c = 0
roots = []
if ARGV.count == 0
  roots = [Pathname.new(".")]
else
  ARGV.each do |v|
    roots << Pathname.new(v)
  end
end

roots.each do |root_path|
  STDERR.puts "Gather filesizes in '#{root_path}'"
  scan_dir(db, root_path) do |path|
    db.execute("INSERT INTO files VALUES(?, null, null, ?)", path.size, path.realpath.to_s)
  end
  STDERR.puts ""
end

c = 0
STDERR.puts "Hash initial parts of files with same size..."
db.execute("SELECT filesize FROM files GROUP BY filesize HAVING count(filesize) > 1").each do |row|
   db.execute("SELECT path FROM files where filesize = ?", row[0]).each do |pathrow|
      path = pathrow[0]
      c += 1
      print_clear(path)
      # Files with exactly the same filesize are candidate duplicates. everything else is different
      init_digest = Digest::SHA1.new
      init_digest << (File.read(path, 4096) || "")
      db.execute("UPDATE files SET init_digest = ? WHERE path = ?", init_digest.digest, path)
   end
end
print_clear("  done (#{c} files)")
STDERR.puts ""

# iterate POSSIBLE duplicates (lengths match, initial hash matches) and do a full hash to confirm
STDERR.puts "Identify exact matches..."
db.execute("SELECT init_digest FROM files WHERE init_digest is not null GROUP BY init_digest HAVING count(init_digest) > 1").each do |row|
  db.execute("SELECT path FROM files WHERE init_digest = ?", row[0]).each do |frow|
     file = frow[0]
     full_digest = Digest::SHA1.new
     c += 1
     print_clear(file)
     File.open(file, 'r') do |h|
        while buffer = h.read(4096)
           full_digest << buffer
        end
     end
     db.execute("UPDATE files SET full_digest = ? WHERE path = ?", full_digest.digest, file)
  end
end
print_clear("done (#{c} possible duplicates checked)")
STDERR.puts "\n Output Duplicates"

# Now we can query for exact matches, which will go to stdout
db.execute("SELECT full_digest FROM files WHERE full_digest IS NOT null GROUP BY full_digest HAVING count(full_digest) > 1 ").each do |row|

  puts(":: " + Base64.encode64(row[0]))
  db.execute("SELECT path FROM files WHERE full_digest = ?", row[0]).each do |f|
      puts f[0]
  end
  puts ""
end
